#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å®Œæ•´æå–CNKGraph.Writings.xmlä¸­çš„æœç”«æ•°æ®åˆ°ä¸‰ä¸ªCSVæ–‡ä»¶
åŸºäºæœ€æ–°çš„åŸç”Ÿç‰¹å¾è®¾è®¡
"""

import xml.etree.ElementTree as ET
import json
import csv
from datetime import datetime
from collections import defaultdict
import os

def extract_dufu_data_to_csv():
    """æå–æœç”«æ•°æ®åˆ°å››ä¸ªCSVæ–‡ä»¶"""
    print("ğŸš€ å¼€å§‹æå–CNKGraph.Writings.xmlä¸­çš„æœç”«æ•°æ®...")
    
    xml_file = "CNKGraph.Writings.xml"
    
    # åˆå§‹åŒ–æ•°æ®æ”¶é›†å™¨
    database_metadata = {}  # æ•°æ®åº“å…ƒæ•°æ®
    dufu_metadata = {}      # æœç”«å…ƒæ•°æ®
    dufu_poems = []
    timeline_data = defaultdict(lambda: {
        'poems_count': 0,
        'poem_ids': [],
        'group_numbers': [],
        'place_codes': [],
        'poem_types': defaultdict(int),
        'rhyme_categories': defaultdict(int),
        'has_source_books': 0,
        'total_allusions': 0,
        'total_annotations': 0,
        'annotation_types': defaultdict(int),
        'total_lines': 0,
        'has_title_count': 0,
        'group_poems_count': 0,
        'unique_places': set()
    })
    
    # æœç”«ä¸“å±ç»Ÿè®¡
    dufu_stats = {
        'creation_dates': defaultdict(int),
        'places': defaultdict(int),
        'poem_types': defaultdict(int),
        'rhyme_categories': defaultdict(int),
        'poem_type_details': defaultdict(int),
        'dynasties': defaultdict(int),
        'years_range': set(),
        'places_count': set(),
        'group_numbers': set(),
        'author_ids': set(),
        'has_final_rhyme': 0,
        'has_title_poems': 0,
        'poems_with_allusions': 0,
        'poems_with_annotations': 0,
        'total_lines_count': 0,
        'poems_with_source_books': 0,
        'annotation_types_distribution': defaultdict(int)
    }
    
    # ç»Ÿè®¡ä¿¡æ¯
    stats = {
        'total_poems': 0,
        'dufu_poems': 0,
        'dufu_mentions': 0,
        'dynasties': set(),
        'poem_types': defaultdict(int),
        'annotation_types': defaultdict(int),
        'earliest_date': None,
        'latest_date': None
    }
    
    try:
        print("ğŸ“„ è§£æXMLæ–‡ä»¶...")
        
        # è§£æXMLæ ¹å…ƒç´ ä¿¡æ¯ - æ•°æ®åº“å…ƒæ•°æ®
        tree = ET.parse(xml_file)
        root = tree.getroot()
        
        # æå–æ ¹å…ƒç´ database_metadata
        database_metadata.update({
            'dataset_name': 'CNKGraph.Writings',
            'xml_version': '1.0',  # ä»XMLå£°æ˜è·å–
            'xml_encoding': 'utf-8',
            'namespace_xsi': root.get('{http://www.w3.org/2001/XMLSchema-instance}schemaLocation', ''),
            'namespace_xsd': 'http://www.w3.org/2001/XMLSchema',
            'max_id': root.get('MaxId', ''),
            'extraction_timestamp': datetime.now().isoformat()
        })
        
        print(f"ğŸ“Š XML MaxId: {database_metadata['max_id']}")
        
        # ä½¿ç”¨è¿­ä»£è§£æå¤„ç†å¤§æ–‡ä»¶
        print("ğŸ” å¼€å§‹è¿­ä»£è§£æè¯—æ­Œæ•°æ®...")
        context = ET.iterparse(xml_file, events=("start", "end"))
        context = iter(context)
        event, root = next(context)
        
        for event, elem in context:
            if event == "end" and elem.tag == "Poem":
                stats['total_poems'] += 1
                
                # è·å–è¯—æ­ŒåŸºæœ¬å±æ€§
                poem_id = elem.get('Id', '')
                dynasty = elem.get('D', '')
                author = elem.get('AU', '')
                author_id = elem.get('AId', '')
                
                stats['dynasties'].add(dynasty)
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯æœç”«çš„ä½œå“
                if author == 'æœç”«':
                    stats['dufu_poems'] += 1
                    
                    # æå–å®Œæ•´è¯—æ­Œä¿¡æ¯
                    poem_data = extract_poem_data(elem)
                    dufu_poems.append(poem_data)
                    
                    # æ›´æ–°æœç”«ä¸“å±ç»Ÿè®¡
                    update_dufu_stats(poem_data, dufu_stats)
                    
                    # æ›´æ–°æ—¶é—´åºåˆ—æ•°æ®
                    update_timeline_data(poem_data, timeline_data)
                    
                    # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
                    poem_type = poem_data.get('poem_type', '')
                    if poem_type:
                        stats['poem_types'][poem_type] += 1
                    
                    # æ›´æ–°æ—¥æœŸèŒƒå›´
                    creation_date = poem_data.get('creation_date_raw', '')
                    if creation_date:
                        if not stats['earliest_date'] or creation_date < stats['earliest_date']:
                            stats['earliest_date'] = creation_date
                        if not stats['latest_date'] or creation_date > stats['latest_date']:
                            stats['latest_date'] = creation_date
                
                # æ£€æŸ¥æœç”«è¢«æåŠ
                xml_str = ET.tostring(elem, encoding='unicode')
                if 'æœç”«' in xml_str and author != 'æœç”«':
                    stats['dufu_mentions'] += 1
                
                # æ¸…ç†å†…å­˜
                elem.clear()
                root.clear()
                
                # è¿›åº¦æ˜¾ç¤º
                if stats['total_poems'] % 100000 == 0:
                    print(f"   å·²å¤„ç† {stats['total_poems']:,} é¦–è¯—æ­Œï¼Œå‘ç°æœç”«ä½œå“ {stats['dufu_poems']} é¦–")
        
        # å®Œå–„database_metadata
        database_metadata.update({
            'total_poems_count': stats['total_poems'],
            'dufu_poems_count': stats['dufu_poems'],
            'dufu_mentions_count': stats['dufu_mentions'],
            'dynasties_list': list(stats['dynasties']),
            'extraction_completed': True
        })
        
        # ç”Ÿæˆæœç”«å…ƒæ•°æ®
        dufu_metadata = generate_dufu_metadata(dufu_stats, dufu_poems)
        
        print(f"\nâœ… æ•°æ®æå–å®Œæˆï¼")
        print(f"   ğŸ“š æ€»è¯—æ­Œæ•°: {stats['total_poems']:,}")
        print(f"   âœï¸ æœç”«ä½œå“: {stats['dufu_poems']:,}")
        print(f"   ğŸ“ æœç”«è¢«æåŠ: {stats['dufu_mentions']:,}")
        
        # ç”ŸæˆCSVæ–‡ä»¶
        generate_csv_files(database_metadata, dufu_metadata, dufu_poems, timeline_data)
        
        return database_metadata, dufu_metadata, dufu_poems, timeline_data
        
    except Exception as e:
        print(f"âŒ æå–å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None, None, None

def extract_poem_data(poem_elem):
    """ä»XMLå…ƒç´ æå–å®Œæ•´çš„è¯—æ­Œæ•°æ®"""
    poem_data = {}
    
    # åŸºæœ¬å±æ€§
    poem_data['poem_id'] = poem_elem.get('Id', '')
    poem_data['group_number'] = poem_elem.get('G', '')
    poem_data['dynasty'] = poem_elem.get('D', '')
    poem_data['author'] = poem_elem.get('AU', '')
    poem_data['author_id'] = poem_elem.get('AId', '')
    poem_data['creation_date_raw'] = poem_elem.get('AD', '')
    poem_data['place_code'] = poem_elem.get('AP', '')
    poem_data['poem_type'] = poem_elem.get('T', '')
    poem_data['poem_type_detail'] = poem_elem.get('TD', '')
    poem_data['rhyme_category'] = poem_elem.get('R', '')
    poem_data['rhyme_number'] = poem_elem.get('RA', '')
    poem_data['final_rhyme'] = poem_elem.get('FR', '')
    poem_data['has_title'] = poem_elem.get('TS', '') == 'true'
    
    # æ ‡é¢˜ä¿¡æ¯
    title_elem = poem_elem.find('Title')
    if title_elem is not None:
        poem_data['title_text'] = title_elem.get('C', '')
        title_annotations = extract_annotations(title_elem.find('Ns'))
        poem_data['title_annotations'] = json.dumps(title_annotations, ensure_ascii=False)
    else:
        poem_data['title_text'] = ''
        poem_data['title_annotations'] = json.dumps({}, ensure_ascii=False)
    
    # æ¥æºæ–‡çŒ®
    fs_elem = poem_elem.find('Fs')
    if fs_elem is not None:
        source_books = [f.text for f in fs_elem.findall('F') if f.text]
        poem_data['source_books'] = json.dumps(source_books, ensure_ascii=False)
    else:
        poem_data['source_books'] = json.dumps([], ensure_ascii=False)
    
    # å…¸æ•…ä¿¡æ¯
    as_elem = poem_elem.find('As')
    if as_elem is not None:
        allusions = []
        for a in as_elem.findall('A'):
            allusion = {
                'ai': a.get('AI', ''),
                'si': a.get('SI', ''),
                'text': a.text or ''
            }
            allusions.append(allusion)
        poem_data['allusion_info'] = json.dumps(allusions, ensure_ascii=False)
    else:
        poem_data['allusion_info'] = json.dumps([], ensure_ascii=False)
    
    # è¯—å¥å†…å®¹
    jus_elem = poem_elem.find('Jus')
    if jus_elem is not None:
        lines = []
        tones = []
        rhymes = []
        line_annotations = []
        
        for ju in jus_elem.findall('Ju'):
            lines.append(ju.get('C', ''))
            tones.append(ju.get('T', ''))
            rhymes.append(ju.get('R', ''))
            
            # æå–è¯¥å¥çš„æ³¨é‡Š
            ju_annotations = extract_annotations(ju.find('Ns'))
            line_annotations.append(ju_annotations)
        
        poem_data['poem_content_lines'] = json.dumps(lines, ensure_ascii=False)
        poem_data['poem_lines_tones'] = json.dumps(tones, ensure_ascii=False)
        poem_data['poem_lines_rhymes'] = json.dumps(rhymes, ensure_ascii=False)
        poem_data['line_annotations'] = json.dumps(line_annotations, ensure_ascii=False)
    else:
        poem_data['poem_content_lines'] = json.dumps([], ensure_ascii=False)
        poem_data['poem_lines_tones'] = json.dumps([], ensure_ascii=False)
        poem_data['poem_lines_rhymes'] = json.dumps([], ensure_ascii=False)
        poem_data['line_annotations'] = json.dumps([], ensure_ascii=False)
    
    # åˆ†ç±»æ³¨é‡Š
    all_annotations = extract_all_annotations(poem_elem)
    poem_data['text_annotations'] = json.dumps(all_annotations['Text'], ensure_ascii=False)
    poem_data['word_dict_annotations'] = json.dumps(all_annotations['WordDictInJson'], ensure_ascii=False)
    poem_data['char_dict_annotations'] = json.dumps(all_annotations['CharDictInJson'], ensure_ascii=False)
    poem_data['allusion_key_annotations'] = json.dumps(all_annotations['AllusionKey'], ensure_ascii=False)
    poem_data['image_annotations'] = json.dumps(all_annotations['Image'], ensure_ascii=False)
    
    # å¥å­ç´¢å¼•
    sis_elem = poem_elem.find('SIs')
    if sis_elem is not None:
        sentence_indices = []
        for si in sis_elem.findall('SI'):
            indices = [int(i.text) for i in si.findall('int') if i.text and i.text.isdigit()]
            sentence_indices.append(indices)
        poem_data['sentence_indices'] = json.dumps(sentence_indices, ensure_ascii=False)
    else:
        poem_data['sentence_indices'] = json.dumps([], ensure_ascii=False)
    
    return poem_data

def extract_annotations(ns_elem):
    """æå–Nså…ƒç´ ä¸‹çš„æ‰€æœ‰æ³¨é‡Š"""
    annotations = []
    if ns_elem is not None:
        for n in ns_elem.findall('N'):
            annotation = {
                'type': n.get('T', ''),
                'index': n.get('I', ''),
                'content': n.text or ''
            }
            annotations.append(annotation)
    return annotations

def extract_all_annotations(poem_elem):
    """æå–è¯—æ­Œä¸­æ‰€æœ‰ç±»å‹çš„æ³¨é‡Š"""
    annotations = {
        'Text': [],
        'WordDictInJson': [],
        'CharDictInJson': [],
        'AllusionKey': [],
        'Image': []
    }
    
    # é€’å½’æŸ¥æ‰¾æ‰€æœ‰Nå…ƒç´ 
    for n in poem_elem.iter('N'):
        n_type = n.get('T', '')
        if n_type in annotations:
            annotation = {
                'index': n.get('I', ''),
                'content': n.text or ''
            }
            annotations[n_type].append(annotation)
    
    return annotations

def update_dufu_stats(poem_data, dufu_stats):
    """æ›´æ–°æœç”«ä¸“å±ç»Ÿè®¡æ•°æ®"""
    # åˆ›ä½œæ—¶é—´ç»Ÿè®¡
    creation_date = poem_data.get('creation_date_raw', '')
    if creation_date:
        dufu_stats['creation_dates'][creation_date] += 1
        # æå–å¹´ä»½
        year_match = creation_date[:4] if len(creation_date) >= 4 else creation_date
        dufu_stats['years_range'].add(year_match)
    
    # åœ°ç‚¹ç»Ÿè®¡
    place_code = poem_data.get('place_code', '')
    if place_code:
        dufu_stats['places'][place_code] += 1
        dufu_stats['places_count'].add(place_code)
    
    # è¯—æ­Œç±»å‹ç»Ÿè®¡
    poem_type = poem_data.get('poem_type', '')
    if poem_type:
        dufu_stats['poem_types'][poem_type] += 1
    
    poem_type_detail = poem_data.get('poem_type_detail', '')
    if poem_type_detail:
        dufu_stats['poem_type_details'][poem_type_detail] += 1
    
    # æŠ¼éŸµç»Ÿè®¡
    rhyme_category = poem_data.get('rhyme_category', '')
    if rhyme_category:
        dufu_stats['rhyme_categories'][rhyme_category] += 1
    
    # æœä»£ç»Ÿè®¡
    dynasty = poem_data.get('dynasty', '')
    if dynasty:
        dufu_stats['dynasties'][dynasty] += 1
    
    # ç»„å·ç»Ÿè®¡
    group_number = poem_data.get('group_number', '')
    if group_number:
        dufu_stats['group_numbers'].add(group_number)
    
    # ä½œè€…IDç»Ÿè®¡
    author_id = poem_data.get('author_id', '')
    if author_id:
        dufu_stats['author_ids'].add(author_id)
    
    # ç‰¹æ®Šç‰¹å¾ç»Ÿè®¡
    if poem_data.get('final_rhyme'):
        dufu_stats['has_final_rhyme'] += 1
    
    if poem_data.get('has_title'):
        dufu_stats['has_title_poems'] += 1
    
    # å…¸æ•…ç»Ÿè®¡
    allusion_info = poem_data.get('allusion_info', '[]')
    if allusion_info and allusion_info != '[]':
        dufu_stats['poems_with_allusions'] += 1
    
    # æ¥æºæ–‡çŒ®ç»Ÿè®¡
    source_books = poem_data.get('source_books', '[]')
    if source_books and source_books != '[]':
        dufu_stats['poems_with_source_books'] += 1
    
    # è¯—å¥è¡Œæ•°ç»Ÿè®¡
    poem_lines = poem_data.get('poem_content_lines', '[]')
    if poem_lines and poem_lines != '[]':
        lines = json.loads(poem_lines)
        dufu_stats['total_lines_count'] += len(lines)
    
    # æ³¨é‡Šç±»å‹ç»Ÿè®¡
    for annotation_type in ['text_annotations', 'word_dict_annotations', 'char_dict_annotations', 
                           'allusion_key_annotations', 'image_annotations']:
        annotations = poem_data.get(annotation_type, '[]')
        if annotations and annotations != '[]':
            annotation_list = json.loads(annotations)
            if annotation_list:
                dufu_stats['poems_with_annotations'] += 1
                dufu_stats['annotation_types_distribution'][annotation_type] += len(annotation_list)

def generate_dufu_metadata(dufu_stats, dufu_poems):
    """ç”Ÿæˆæœç”«å…ƒæ•°æ®"""
    dufu_metadata = {
        # åŸºæœ¬ä¿¡æ¯
        'author_name': 'æœç”«',
        'total_poems_count': len(dufu_poems),
        'author_id': list(dufu_stats['author_ids'])[0] if dufu_stats['author_ids'] else '',
        'extraction_timestamp': datetime.now().isoformat(),
        
        # æ—¶é—´è·¨åº¦
        'earliest_year': min(dufu_stats['years_range']) if dufu_stats['years_range'] else '',
        'latest_year': max(dufu_stats['years_range']) if dufu_stats['years_range'] else '',
        'total_years_span': len(dufu_stats['years_range']),
        'creation_dates_count': len(dufu_stats['creation_dates']),
        'most_productive_date': max(dufu_stats['creation_dates'].items(), key=lambda x: x[1])[0] if dufu_stats['creation_dates'] else '',
        'most_productive_date_count': max(dufu_stats['creation_dates'].values()) if dufu_stats['creation_dates'] else 0,
        
        # åœ°ç†åˆ†å¸ƒ
        'total_places_count': len(dufu_stats['places_count']),
        'most_frequent_place': max(dufu_stats['places'].items(), key=lambda x: x[1])[0] if dufu_stats['places'] else '',
        'most_frequent_place_count': max(dufu_stats['places'].values()) if dufu_stats['places'] else 0,
        'places_distribution': json.dumps(dict(dufu_stats['places']), ensure_ascii=False),
        
        # è¯—æ­Œä½“è£
        'poem_types_count': len(dufu_stats['poem_types']),
        'most_common_poem_type': max(dufu_stats['poem_types'].items(), key=lambda x: x[1])[0] if dufu_stats['poem_types'] else '',
        'most_common_poem_type_count': max(dufu_stats['poem_types'].values()) if dufu_stats['poem_types'] else 0,
        'poem_types_distribution': json.dumps(dict(dufu_stats['poem_types']), ensure_ascii=False),
        'poem_type_details_distribution': json.dumps(dict(dufu_stats['poem_type_details']), ensure_ascii=False),
        
        # æŠ¼éŸµç‰¹å¾
        'rhyme_categories_count': len(dufu_stats['rhyme_categories']),
        'most_used_rhyme': max(dufu_stats['rhyme_categories'].items(), key=lambda x: x[1])[0] if dufu_stats['rhyme_categories'] else '',
        'most_used_rhyme_count': max(dufu_stats['rhyme_categories'].values()) if dufu_stats['rhyme_categories'] else 0,
        'rhyme_categories_distribution': json.dumps(dict(dufu_stats['rhyme_categories']), ensure_ascii=False),
        
        # ç‰¹æ®Šç‰¹å¾
        'has_final_rhyme_count': dufu_stats['has_final_rhyme'],
        'has_title_poems_count': dufu_stats['has_title_poems'],
        'poems_with_allusions_count': dufu_stats['poems_with_allusions'],
        'poems_with_annotations_count': dufu_stats['poems_with_annotations'],
        'poems_with_source_books_count': dufu_stats['poems_with_source_books'],
        'total_lines_count': dufu_stats['total_lines_count'],
        'average_lines_per_poem': dufu_stats['total_lines_count'] / len(dufu_poems) if dufu_poems else 0,
        
        # ç»„ç»‡ç‰¹å¾
        'group_numbers_count': len(dufu_stats['group_numbers']),
        'dynasties_distribution': json.dumps(dict(dufu_stats['dynasties']), ensure_ascii=False),
        'annotation_types_distribution': json.dumps(dict(dufu_stats['annotation_types_distribution']), ensure_ascii=False),
        
        # è®¡ç®—ç™¾åˆ†æ¯”
        'titled_poems_percentage': (dufu_stats['has_title_poems'] / len(dufu_poems) * 100) if dufu_poems else 0,
        'poems_with_allusions_percentage': (dufu_stats['poems_with_allusions'] / len(dufu_poems) * 100) if dufu_poems else 0,
        'poems_with_source_books_percentage': (dufu_stats['poems_with_source_books'] / len(dufu_poems) * 100) if dufu_poems else 0,
        'poems_with_annotations_percentage': (dufu_stats['poems_with_annotations'] / len(dufu_poems) * 100) if dufu_poems else 0
    }
    
    return dufu_metadata

def update_timeline_data(poem_data, timeline_data):
    """æ›´æ–°æ—¶é—´åºåˆ—æ•°æ®"""
    time_period = poem_data.get('creation_date_raw', 'æœªçŸ¥')
    if not time_period:
        time_period = 'æœªçŸ¥'
    
    tl = timeline_data[time_period]
    tl['poems_count'] += 1
    tl['poem_ids'].append(poem_data['poem_id'])
    
    if poem_data.get('group_number'):
        tl['group_numbers'].append(poem_data['group_number'])
        tl['group_poems_count'] += 1
    
    if poem_data.get('place_code'):
        tl['place_codes'].append(poem_data['place_code'])
        tl['unique_places'].add(poem_data['place_code'])
    
    if poem_data.get('poem_type'):
        tl['poem_types'][poem_data['poem_type']] += 1
    
    if poem_data.get('rhyme_category'):
        tl['rhyme_categories'][poem_data['rhyme_category']] += 1
    
    if poem_data.get('source_books') and poem_data['source_books'] != '[]':
        tl['has_source_books'] += 1
    
    if poem_data.get('allusion_info') and poem_data['allusion_info'] != '[]':
        allusions = json.loads(poem_data['allusion_info'])
        tl['total_allusions'] += len(allusions)
    
    if poem_data.get('poem_content_lines'):
        lines = json.loads(poem_data['poem_content_lines'])
        tl['total_lines'] += len(lines)
    
    if poem_data.get('has_title'):
        tl['has_title_count'] += 1

def generate_csv_files(database_metadata, dufu_metadata, dufu_poems, timeline_data):
    """ç”Ÿæˆå››ä¸ªCSVæ–‡ä»¶"""
    print("\nğŸ’¾ ç”ŸæˆCSVæ–‡ä»¶...")
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # 1. ç”Ÿæˆdatabase_metadata.csv - æ•°æ®åº“å…ƒæ•°æ®
    db_metadata_file = f"database_metadata_{timestamp}.csv"
    with open(db_metadata_file, 'w', newline='', encoding='utf-8') as f:
        if database_metadata:
            writer = csv.DictWriter(f, fieldnames=database_metadata.keys())
            writer.writeheader()
            writer.writerow(database_metadata)
    print(f"âœ… {db_metadata_file} - æ•°æ®åº“å…ƒæ•°æ®æ–‡ä»¶")
    
    # 2. ç”Ÿæˆdufu_metadata.csv - æœç”«å…ƒæ•°æ®
    dufu_metadata_file = f"dufu_metadata_{timestamp}.csv"
    with open(dufu_metadata_file, 'w', newline='', encoding='utf-8') as f:
        if dufu_metadata:
            writer = csv.DictWriter(f, fieldnames=dufu_metadata.keys())
            writer.writeheader()
            writer.writerow(dufu_metadata)
    print(f"âœ… {dufu_metadata_file} - æœç”«å…ƒæ•°æ®æ–‡ä»¶")
    
    # 3. ç”Ÿæˆdufu_poems.csv - æœç”«è¯—æ­Œæ–‡ä»¶
    poems_file = f"dufu_poems_{timestamp}.csv"
    if dufu_poems:
        with open(poems_file, 'w', newline='', encoding='utf-8') as f:
            writer = csv.DictWriter(f, fieldnames=dufu_poems[0].keys())
            writer.writeheader()
            writer.writerows(dufu_poems)
    print(f"âœ… {poems_file} - æœç”«è¯—æ­Œæ–‡ä»¶ ({len(dufu_poems)} é¦–)")
    
    # 4. ç”Ÿæˆdufu_timeline.csv - æ—¶é—´åºåˆ—æ–‡ä»¶
    timeline_list = []
    for time_period, data in timeline_data.items():
        timeline_row = {
            'time_period': time_period,
            'poems_count': data['poems_count'],
            'poem_ids': json.dumps(data['poem_ids'], ensure_ascii=False),
            'group_numbers': json.dumps(list(set(data['group_numbers'])), ensure_ascii=False),
            'place_codes': json.dumps(list(set(data['place_codes'])), ensure_ascii=False),
            'poem_types': json.dumps(dict(data['poem_types']), ensure_ascii=False),
            'rhyme_categories': json.dumps(dict(data['rhyme_categories']), ensure_ascii=False),
            'has_source_books': data['has_source_books'],
            'total_allusions': data['total_allusions'],
            'total_annotations': data['total_annotations'],
            'annotation_types': json.dumps(dict(data['annotation_types']), ensure_ascii=False),
            'total_lines': data['total_lines'],
            'has_title_count': data['has_title_count'],
            'group_poems_count': data['group_poems_count'],
            'unique_places_count': len(data['unique_places'])
        }
        timeline_list.append(timeline_row)
    
    timeline_file = f"dufu_timeline_{timestamp}.csv"
    if timeline_list:
        with open(timeline_file, 'w', newline='', encoding='utf-8') as f:
            writer = csv.DictWriter(f, fieldnames=timeline_list[0].keys())
            writer.writeheader()
            writer.writerows(timeline_list)
    print(f"âœ… {timeline_file} - æ—¶é—´åºåˆ—æ–‡ä»¶ ({len(timeline_list)} ä¸ªæ—¶æœŸ)")
    
    print(f"\nğŸ‰ æ‰€æœ‰CSVæ–‡ä»¶ç”Ÿæˆå®Œæˆï¼")
    print(f"ğŸ“ æ–‡ä»¶ä½ç½®: å½“å‰ç›®å½•")
    
    return db_metadata_file, dufu_metadata_file, poems_file, timeline_file

if __name__ == "__main__":
    print("ğŸ“œ æœç”«æ•°æ®æå–å™¨ - CNKGraph.Writings.xml")
    print("="*60)
    
    # æ£€æŸ¥XMLæ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists("CNKGraph.Writings.xml"):
        print("âŒ æœªæ‰¾åˆ° CNKGraph.Writings.xml æ–‡ä»¶")
        print("è¯·ç¡®ä¿XMLæ–‡ä»¶åœ¨å½“å‰ç›®å½•ä¸­")
        exit(1)
    
    # æ‰§è¡Œæå–
    db_metadata, dufu_metadata, poems, timeline = extract_dufu_data_to_csv()
    
    if db_metadata and dufu_metadata and poems and timeline:
        print("="*60)
        print("ğŸ‰ æ•°æ®æå–æˆåŠŸå®Œæˆï¼")
        print("ğŸ“Š ç”Ÿæˆçš„æ–‡ä»¶:")
        print("   1. database_metadata_*.csv - æ•°æ®åº“å…ƒæ•°æ®")
        print("   2. dufu_metadata_*.csv - æœç”«ä½œå“å…ƒæ•°æ®") 
        print("   3. dufu_poems_*.csv - æœç”«è¯—æ­Œè¯¦ç»†æ•°æ®")
        print("   4. dufu_timeline_*.csv - æœç”«æ—¶é—´åºåˆ—æ•°æ®")
    else:
        print("âŒ æ•°æ®æå–å¤±è´¥")
